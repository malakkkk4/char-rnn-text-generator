{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOk1lSZ+L4KmTRMaBn5//HL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malakkkk4/char-rnn-text-generator/blob/main/literature_corpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yXE2RCqXzCr-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('literature_corpus.txt','r')as file:\n",
        "  text=file.read()\n",
        "text=text.lower().replace('\\n',' ')\n",
        "chars=sorted(list(set(text)))\n",
        "print(\"Number of unique characters: \",len(chars))\n",
        "\n",
        "char_to_int= {char:i for i,char in enumerate(chars)}\n",
        "int_to_char= {i: char for i ,char in enumerate(chars)}\n",
        "encoded_text= [char_to_int[char] for char in text]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4klXEIOzniR",
        "outputId": "9805b830-b0de-4c82-cc89-f40580a9893f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique characters:  76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst 100 characters of text: \")\n",
        "print(text[:100])\n",
        "print(\"\\nNumber of characters in text: \",len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea4MYR9S0rAO",
        "outputId": "7258a844-6413-430e-909e-a90d34754ded"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 100 characters of text: \n",
            "﻿the project gutenberg ebook of moby dick; or, the whale      this ebook is for the use of anyone an\n",
            "\n",
            "Number of characters in text:  1238226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(SimpleRNN(units=128,input_shape=(100,1),return_sequences=False))\n",
        "model.add(Dense(len(chars),activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVIxDp072GYQ",
        "outputId": "7097d226-e881-4261-8350-4a3453c7d23c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ZBixV0Bm2q94",
        "outputId": "1aaa341d-39ef-4ed1-a881-8355a9124628"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m76\u001b[0m)             │         \u001b[38;5;34m9,804\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,804</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,444\u001b[0m (103.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,444</span> (103.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,444\u001b[0m (103.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,444</span> (103.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100\n",
        "X=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(0,len(encoded_text)-seq_length,1):\n",
        "  seq_in=encoded_text[i:i + seq_length]\n",
        "  seq_out=encoded_text[i + seq_length]\n",
        "  X.append(seq_in)\n",
        "  y.append(seq_out)\n",
        "\n",
        "X=np.reshape(X,(len(X),seq_length,1))\n",
        "X =X/float(len(chars))\n",
        "\n",
        "y=to_categorical(y,num_classes=len(chars))\n",
        "\n",
        "model.fit(X,y,epochs=50,batch_size=128,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFY7GGne2-tv",
        "outputId": "bbd6c2af-242f-46b8-d813-f2695a0f7ffc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 8ms/step - loss: 2.8408\n",
            "Epoch 2/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.6554\n",
            "Epoch 3/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.5688\n",
            "Epoch 4/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.5028\n",
            "Epoch 5/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.4654\n",
            "Epoch 6/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.4387\n",
            "Epoch 7/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.4158\n",
            "Epoch 8/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.4028\n",
            "Epoch 9/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.3883\n",
            "Epoch 10/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3738\n",
            "Epoch 11/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3610\n",
            "Epoch 12/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.3518\n",
            "Epoch 13/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3415\n",
            "Epoch 14/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3327\n",
            "Epoch 15/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3254\n",
            "Epoch 16/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3200\n",
            "Epoch 17/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3148\n",
            "Epoch 18/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.3032\n",
            "Epoch 19/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2997\n",
            "Epoch 20/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 2.2937\n",
            "Epoch 21/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2883\n",
            "Epoch 22/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.2833\n",
            "Epoch 23/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2778\n",
            "Epoch 24/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2754\n",
            "Epoch 25/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.2719\n",
            "Epoch 26/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.2651\n",
            "Epoch 27/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2613\n",
            "Epoch 28/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.2577\n",
            "Epoch 29/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2586\n",
            "Epoch 30/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2557\n",
            "Epoch 31/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2932\n",
            "Epoch 32/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.3503\n",
            "Epoch 33/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.3143\n",
            "Epoch 34/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.2953\n",
            "Epoch 35/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2826\n",
            "Epoch 36/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2709\n",
            "Epoch 37/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2698\n",
            "Epoch 38/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2594\n",
            "Epoch 39/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2536\n",
            "Epoch 40/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2457\n",
            "Epoch 41/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2434\n",
            "Epoch 42/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2485\n",
            "Epoch 43/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2326\n",
            "Epoch 44/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2288\n",
            "Epoch 45/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2978\n",
            "Epoch 46/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 2.3056\n",
            "Epoch 47/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2728\n",
            "Epoch 48/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2495\n",
            "Epoch 49/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 2.2551\n",
            "Epoch 50/50\n",
            "\u001b[1m9673/9673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 2.2469\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ce955b4cc80>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new text\n",
        "seed_text = \"call me ishmael\"\n",
        "generated_text = seed_text\n",
        "encoded_seq = [char_to_int[char] for char in seed_text]\n",
        "\n",
        "for _ in range(500):\n",
        "    # Prepare the input shape\n",
        "    encoded_seq_reshaped = np.reshape(encoded_seq, (1, len(encoded_seq), 1))\n",
        "    encoded_seq_reshaped = encoded_seq_reshaped / float(len(chars))\n",
        "\n",
        "    # Predict the next character\n",
        "    prediction = model.predict(encoded_seq_reshaped, verbose=0)\n",
        "    predicted_index = np.argmax(prediction)\n",
        "    next_char = int_to_char[predicted_index]\n",
        "\n",
        "    generated_text += next_char\n",
        "    encoded_seq.append(predicted_index)\n",
        "    encoded_seq = encoded_seq[1:]  # Move the window\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "Z04vnEhArAqE",
        "outputId": "fbb03ff4-96a9-42b1-d22f-6ef4e3b33a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "call me ishmaelu and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the shate and the \n"
          ]
        }
      ]
    }
  ]
}